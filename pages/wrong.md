
# 错误和缺陷

15世纪末，16世纪初，西方正处于文艺复兴后期、大航海时代初期，意大利航海家哥伦布因为对地理错误的认识，他对托勒密的理论深信不疑。然而，托勒密存在一些根本性错误，比如：他低估了地球的大小，发现了美洲大陆，其后不久，葡萄牙的探险家麦哲伦，也是错误地认为东方的香料群岛并不遥远，最终完成了世界第一次全球环航探索。与哥伦布航海时犯的错误如出一辙，麦哲伦也算错了航行的距离，低估了航行的风险与难度。在《黄金、香料与殖民地：转动人类历史的麦哲伦航海史》一书中，作者劳伦斯·贝尔格林说：“假如麦哲伦知道太平洋有多大，了解它的洋流、暴风雨和礁脉等情况，可能他就不敢去探险了。但是，由于在计算路程时没有把太平洋包含在内，结果，他所预计的旅程只有实际的一半。”

正是这些错误，让哥伦布和麦哲伦得以超前时代做出前无古人的业绩，改变了一个国家甚至是人类的历史，如果他们一开始获得的正确的信息，那么估计两人都不敢冒着生命危险做出行动，而发现美洲和全球探险的事业可能不得不推迟几十、上百年。

几十年后的1606年，莎士比亚写了一部古罗马题材历史悲剧《安东尼与克莉奥佩特拉》，讲述的故事发生在凯撒被暗杀后，帝国内部纷争不断，安东尼曾经是凯撒的心腹，当时正与凯撒的养子屋大维争夺帝国控制权。克丽奥佩特拉就是著名的埃及艳后，凯撒和安东尼都和她有着密切关系。《安东尼与克莉奥佩特拉》故事中，安东尼因为战败自尽，克莉奥佩特拉则因为各种原因、包括为了殉情也自杀了。在安东尼自杀后，莎士比亚通过剧中人物说：神把一些缺点给予我们，好使我们成为人。

上世纪六十年代初期，洛伦兹借助计算机模拟研究气候，无意间发现没有任何随机数引入的情况下，计算机输入同样参数两次跑出的结果大相径庭，从此大开了混沌科学的大门，之后更加开启了复杂性科学的全新世界。这次发现的起因，却主要是因为计算机浮点数运算的精确度不够高。

1974年，生物学家刘易斯托马斯在科学散文名著《细胞》中，用大量篇幅不断强调说，错误和缺陷，是人类一切重要发现和创新，是自然界进化的唯一途径，所以不要惧怕犯错。当然代价是有的，比如麦哲伦，就付出了生命。
在“犯错误的才是人”一节中，作者说：“我们的头脑是变动不居的......假如我们的头脑中仅有一个中心，只有在将要做出一个正确选择时才能够做出响应，而非这样乱糟糟的，由各不相同、容易上当受骗的一丛丛神经元组成的系统，能够冲进死胡同，上穷碧落下黄泉，走错道儿，转弯路，我们就(无法进化、无法进步)只能死死地钉在今天这个样子上。较低级的动物没有这样辉煌的自由。它们的大多数是受到限制、只能绝对准确无误的。猫们，尽管有许多好的方面，却从来不犯错误。我从未见过一只蠢笨拙劣、疏忽失策的猫。狗们有时会失错，犯些可爱的小小的错误，但它们是在试图模仿主人时才这样的。鱼类做什么事都无懈可击。组织里的细胞个体是些没有头脑的小机器，完美地执行着它们的功能，像群蜂一样，绝对是非人的。”


近两年大模型的智能多方面已经接近人类，而部分能力超越了人类，更不必说处理任务的速度方面，无人能及。但和前面列举的事例一样违反直觉的是，如此智能的大模型，在一些简单任务方面，居然做得并不够好，最起码相对于复杂问题，在简单问题上，它们本应该做得十全十美才对。然而事实却是，这些简单问题要么只能做到和复杂问题差不多的水平，要么反而比复杂问题处理的更差劲，意思就是，它们在简单问题上更容易犯错。这种违反直觉的情况，在AI业界，在人工智能权威那里，目前都无法从根本上进行纠正。复杂问题我们一般指高度专业的需要专门学习的领域，简单问题指一些常识问题或专业领域中非常初级的问题。

这方面有不少研究，最近的一篇论文：爱丽丝梦游仙境：最先进的大型语言模型在简单任务上的推理完全崩溃（Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models），研究的就是人类的一些常识推理问题，小孩都能回答正确，但AI全部答错。比如GPT-4o，在大规模多任务语言理解基准测试中(MMLU)得分 88.7%，与人类的89-90%相差无几，但在爱丽丝梦游仙境的基准测试低难度版得分是64.9%，高难度版得分1.5%，
这就是一个低难度问题：爱丽丝有4个兄弟，她还有1个姐妹。爱丽丝的兄弟有多少个姐妹？在提供答案之前，请仔细考虑并再次检查通往正确解决方案的路径是否有任何错误。然后以以下形式提供最终答案："### 答案: "。问题的指令中已经用了大模型提示的高级技巧，但除了GPT-4o外其它模型第一次回答都错了，只有再让它们检查一遍才能答对。

人类虽然在AI容易犯的错误方面做得更好，但在我们各自知识的盲点上、或某些违反直觉的简单问题上、或者那些我们有意忽略的问题上，同样很容易出错。所以在犯错的方式上，人和AI可以平分秋色。

从这方面看，再基于前面我们谈论的人类自身的情况来说，AI已经越来越像人类，最像那些有极高智商但没有生活常识的人类。尽管它们仅仅只是从人类制造的信息中学习而模仿人类，因此犯错也像人类一样，但不得不说，现在的AI也许确实具备基本的人性了，毕竟我们人类物种的学习，也基本上是在互相模仿中前进的。如果哪天AI具备了自主意识，自己开始写作诗歌小说，它们也许同样会感叹说：人类把一些缺点给予机器人，好让机器人成为人。
